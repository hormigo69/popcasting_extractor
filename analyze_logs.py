#!/usr/bin/env python3
"""
Script para analizar los logs de extracciÃ³n y generar reportes
"""

import os
import re
from datetime import datetime
from collections import defaultdict, Counter

def analyze_parsing_errors():
    """Analiza los errores de parsing del archivo de log"""
    log_file = "logs/parsing_errors.log"
    
    if not os.path.exists(log_file):
        print("âŒ No se encontrÃ³ el archivo de errores de parsing")
        return
    
    print("ğŸ” ANALIZANDO ERRORES DE PARSING")
    print("=" * 50)
    
    errors_by_podcast = defaultdict(list)
    error_types = Counter()
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
        # Dividir por lÃ­neas que empiecen con timestamp
        lines = re.split(r'\n(?=\d{4}-\d{2}-\d{2})', content)
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Extraer informaciÃ³n del log
            match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) - WARNING - Podcast: (.+?) - (.+)', line)
            if match:
                timestamp, podcast, error_msg = match.groups()
                errors_by_podcast[podcast].append({
                    'timestamp': timestamp,
                    'error': error_msg
                })
                
                # Categorizar tipos de error
                if 'Entrada invÃ¡lida descartada' in error_msg:
                    error_types['Entrada invÃ¡lida'] += 1
                elif 'Entrada sin separador descartada' in error_msg:
                    error_types['Sin separador'] += 1
                elif 'No se pudo parsear' in error_msg:
                    error_types['Parser anterior'] += 1
                else:
                    error_types['Otros'] += 1
    
    # EstadÃ­sticas generales
    total_errors = sum(len(errors) for errors in errors_by_podcast.values())
    total_podcasts_with_errors = len(errors_by_podcast)
    
    print("ğŸ“Š EstadÃ­sticas generales:")
    print(f"   Total de errores: {total_errors}")
    print(f"   Podcasts con errores: {total_podcasts_with_errors}")
    print()
    
    # Tipos de errores
    print("ğŸ“‹ Tipos de errores:")
    for error_type, count in error_types.most_common():
        percentage = (count / total_errors) * 100 if total_errors > 0 else 0
        print(f"   {error_type}: {count} ({percentage:.1f}%)")
    print()
    
    # Podcasts con mÃ¡s errores
    print("ğŸ¯ Podcasts con mÃ¡s errores:")
    sorted_podcasts = sorted(errors_by_podcast.items(), key=lambda x: len(x[1]), reverse=True)
    for podcast, errors in sorted_podcasts[:10]:
        print(f"   {podcast}: {len(errors)} errores")
    print()
    
    # Ejemplos de errores
    print("ğŸ’¡ Ejemplos de errores:")
    for podcast, errors in sorted_podcasts[:3]:
        print(f"   {podcast}:")
        for error in errors[:2]:  # Mostrar solo los primeros 2 errores
            print(f"     - {error['error']}")
        print()

def analyze_extraction_stats():
    """Analiza las estadÃ­sticas de extracciÃ³n del archivo de log"""
    log_file = "logs/extraction_stats.log"
    
    if not os.path.exists(log_file):
        print("âŒ No se encontrÃ³ el archivo de estadÃ­sticas de extracciÃ³n")
        return
    
    print("ğŸ“ˆ ANALIZANDO ESTADÃSTICAS DE EXTRACCIÃ“N")
    print("=" * 50)
    
    extractions = []
    current_extraction = {}
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
        # Dividir por lÃ­neas que empiecen con timestamp
        lines = re.split(r'\n(?=\d{4}-\d{2}-\d{2})', content)
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Extraer informaciÃ³n del log
            match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) - (\w+) - (.+)', line)
            if match:
                timestamp, level, message = match.groups()
                
                if 'Proceso de extracciÃ³n finalizado' in message:
                    if current_extraction:
                        extractions.append(current_extraction)
                    current_extraction = {'timestamp': timestamp}
                elif 'Total de episodios procesados' in message:
                    match = re.search(r'(\d+)', message)
                    if match:
                        current_extraction['episodes'] = int(match.group(1))
                elif 'Total de canciones aÃ±adidas/actualizadas' in message:
                    match = re.search(r'(\d+)', message)
                    if match:
                        current_extraction['songs'] = int(match.group(1))
    
    # AÃ±adir la Ãºltima extracciÃ³n si existe
    if current_extraction:
        extractions.append(current_extraction)
    
    if not extractions:
        print("âŒ No se encontraron datos de extracciÃ³n")
        return
    
    print(f"ğŸ“Š Total de extracciones registradas: {len(extractions)}")
    print()
    
    # EstadÃ­sticas de la Ãºltima extracciÃ³n
    latest = extractions[-1]
    print("ğŸ”„ Ãšltima extracciÃ³n:")
    print(f"   Fecha: {latest['timestamp']}")
    print(f"   Episodios: {latest.get('episodes', 'N/A')}")
    print(f"   Canciones: {latest.get('songs', 'N/A')}")
    print()
    
    # EstadÃ­sticas histÃ³ricas
    if len(extractions) > 1:
        print("ğŸ“ˆ EstadÃ­sticas histÃ³ricas:")
        episodes_list = [e.get('episodes', 0) for e in extractions if 'episodes' in e]
        songs_list = [e.get('songs', 0) for e in extractions if 'songs' in e]
        
        if episodes_list:
            print(f"   Promedio de episodios por extracciÃ³n: {sum(episodes_list) / len(episodes_list):.1f}")
            print(f"   MÃ¡ximo episodios en una extracciÃ³n: {max(episodes_list)}")
            print(f"   MÃ­nimo episodios en una extracciÃ³n: {min(episodes_list)}")
        
        if songs_list:
            print(f"   Promedio de canciones por extracciÃ³n: {sum(songs_list) / len(songs_list):.1f}")
            print(f"   MÃ¡ximo canciones en una extracciÃ³n: {max(songs_list)}")
            print(f"   MÃ­nimo canciones en una extracciÃ³n: {min(songs_list)}")
        print()

def generate_summary_report():
    """Genera un reporte resumido de todos los logs"""
    print("ğŸ“‹ REPORTE RESUMIDO DE LOGS")
    print("=" * 50)
    print(f"ğŸ“… Fecha de anÃ¡lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Verificar archivos de log
    parsing_log = "logs/parsing_errors.log"
    stats_log = "logs/extraction_stats.log"
    
    print("ğŸ“ Archivos de log:")
    print(f"   Errores de parsing: {'âœ…' if os.path.exists(parsing_log) else 'âŒ'} {parsing_log}")
    print(f"   EstadÃ­sticas: {'âœ…' if os.path.exists(stats_log) else 'âŒ'} {stats_log}")
    print()
    
    # Analizar cada tipo de log
    analyze_extraction_stats()
    analyze_parsing_errors()
    
    print("ğŸ‰ AnÃ¡lisis completado!")

if __name__ == "__main__":
    generate_summary_report() 